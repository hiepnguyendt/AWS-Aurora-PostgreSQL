[
{
	"uri": "//localhost:1313/vi/",
	"title": "AWS RDS PostgreSQL",
	"tags": [],
	"description": "",
	"content": "Let start with AWS RDS PostgreSQL Overall In this lab, you\u0026rsquo;ll learn the basics and practice of Amazon RDS PostgreSQL\nContent Introduction Start with PostgreSQL Create RDS PostgreSQL Database Instance Connect to pgAdmin4 Helpful Resources Clean up resources "
},
{
	"uri": "//localhost:1313/vi/6-databaseactivitystreaming/6-1-setupkmsfordatabaseactivitystreamsinaction/",
	"title": "Configure the database client",
	"tags": [],
	"description": "",
	"content": "After Amazon RDS provisions your DB instance, you can use any standard SQL client application to connect to the instance. Before you can connect, the DB instance must be available and accessible. Whether you can connect to the instance from outside the VPC depends on how you created the Amazon RDS DB instance:\nIf you created your DB instance as public, devices and Amazon EC2 instances outside the VPC can connect to your database. If you created your DB instance as private, only Amazon EC2 instances and devices inside the Amazon VPC can connect to your database. title : \u0026ldquo;Setup KMS for Database Activity Streaming\u0026rdquo; date : \u0026ldquo;r Sys.Date()\u0026rdquo; weight : 1 chapter : false pre : \u0026quot; 6.1. \u0026quot; Database Activity Streaming requires a Master Key to encrypt the key that in turn encrypts the logged database activity. The Default AWS RDS KMS key can’t be used as the Master key. Therefore, we need to create a new customer managed KMS key to configure the Database Activity Streaming.\nCreate KMS Key Open KMS console and select Customer Managed Keys on the left-hand side and click on Create Key: On the next screen under Configure key choose Symmetric key type and click Next: On the next screen, under Add Labels give a name for the key under the field Alias such as cmk-apg-lab. Under Description field, type a description for the key such as Customer managed Key for Aurora PostgreSQL Database Activity Streaming (DAS) lab and click Next. On the next screen under Define Key Administrative permissions and Define key usage permissions, leave with default setting.\nOn the next screen, review the policy and click Finish.\nVerify the newly created KMS key on the KMS dashboard. In this chapter, we will use pgAdmin4 to connect to a RDS for PostgreSQL DB instance, so we need create DB as public.\nYou can use the open-source tool pgAdmin4 to connect to your RDS for PostgreSQL DB instance. You can download and install pgAdmin from http://www.pgadmin.org/ without having a local instance of PostgreSQL on your client computer\n1.Launch the pgAdmin4 application on your client computer.\n2.On the Dashboard tab, choose Add New Server. 3.In the Create - Server dialog box, type a name on the General tab to identify the server in pgAdmin4. 4.In the Connection tab, type the following information from your DB instance:\nFor Host, type the endpoint you have retrieve in the step 3.2, for example mypostgresql.c6c8dntfzzhgv0.us-east-2.rds.amazonaws.com. For Port, type the assigned port. For Username, type the user name that you entered when you created the DB instance. For Password, type the password that you entered when you created the DB instance. 5.Choose Save. If you have any problems connecting, see Troubleshooting connections to your RDS for PostgreSQL instance.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "\nAmazon Aurora PostgreSQL là một công cụ cơ sở dữ liệu quan hệ tuân thủ ACID và tương thích với PostgreSQL được quản lý toàn phần bởi AWS, kết hợp giữa tốc độ, độ tin cậy và khả năng quản lý của Amazon Aurora với sự đơn giản và hiệu quả về mặt chi phí của cơ sở dữ liệu mã nguồn mở. Aurora PostgreSQL là giải pháp thay thế tùy ý cho PostgreSQL và giúp việc thiết lập, vận hành cũng như mở rộng quy mô triển khai PostgreSQL mới và hiện có của bạn trở nên đơn giản và tiết kiệm chi phí, từ đó giúp bạn tập trung vào doanh nghiệp và ứng dụng của mình. Để tìm hiểu thêm về Aurora nói chung, hãy xem Amazon Aurora là gì?.\nNgoài các lợi ích của Aurora, Aurora PostgreSQL còn cung cấp một lộ trình chuyển đổi thuận tiện từ Amazon RDS sang Aurora, với các công cụ chuyển đổi giúp chuyển đổi các ứng dụng RDS for PostgreSQL hiện có của bạn sang Aurora PostgreSQL. Các tác vụ cơ sở dữ liệu thông thường như cung cấp, vá lỗi, sao lưu, khôi phục, phát hiện lỗi và sửa chữa cũng dễ dàng quản lý bằng Aurora PostgreSQL. Aurora PostgreSQL có thể làm việc với nhiều tiêu chuẩn ngành. Ví dụ: bạn có thể sử dụng cơ sở dữ liệu Aurora PostgreSQL để xây dựng các ứng dụng tuân thủ HIPAA và lưu trữ thông tin liên quan đến chăm sóc sức khỏe, bao gồm thông tin sức khỏe được bảo vệ (PHI protected health information), theo Thỏa thuận liên kết kinh doanh (BAA Business Associate Agreement ) đã hoàn thành với AWS.\n"
},
{
	"uri": "//localhost:1313/vi/9-testfaulttolerance/9-1-setupfailovereventnotifications/",
	"title": "Set up failover event notifications",
	"tags": [],
	"description": "",
	"content": "To receive notifications when failover events occur with your DB cluster, you will create an Amazon Simple Notification Service (SNS) topic, subscribe your email address to the SNS topic, create an RDS event subscription publishing events to the SNS topic and registering the DB cluster as an event source.\nOpen a Cloud9 terminal window by referring Open Cloud9 Terminal Window section and paste the following command to create an SNS topic.\naws sns create-topic \\\r--name auroralab-cluster-failovers If successful, the command will respond back with a TopicArn identifier, you will need this value in the next command.\nNext, subscribe your email address to the SNS topic using the command below, changing the placeholder [YourEmail] with your email address:\naws sns subscribe \\\r--topic-arn $(aws sns list-topics --query \u0026#39;Topics[?contains(TopicArn,`auroralab-cluster-failovers`)].TopicArn\u0026#39; --output text) \\\r--protocol email \\\r--notification-endpoint \u0026#39;[YourEmail]\u0026#39; You should see Output similar to the following:\nYou will receive a verification email on that address, please confirm the subscription by following the instructions in the email.\nOnce you click Confirm subscription in the email, you\u0026rsquo;ll see a browser window with a confirmation message as follows:\nOnce confirmed, or while you are waiting for the verification email to arrive, create an RDS event subscription and register the DB cluster as an event source using the command below:\nIf your Aurora cluster name is different than aupg-labs-cluster, update the command below accordingly.\naws rds create-event-subscription \\\r--subscription-name auroralab-cluster-failovers \\\r--sns-topic-arn $(aws sns list-topics --query \u0026#39;Topics[?contains(TopicArn,`auroralab-cluster-failovers`)].TopicArn\u0026#39; --output text) \\\r--source-type db-cluster \\\r--event-categories \u0026#39;[\u0026#34;failover\u0026#34;]\u0026#39; \\\r--enabled aws rds add-source-identifier-to-subscription \\\r--subscription-name auroralab-cluster-failovers \\\r--source-identifier aupg-fcj-labs At this time the event notifications have been configured. Ensure you have verified your email address before proceeding to the next section.\n"
},
{
	"uri": "//localhost:1313/vi/5-clustercachemanagement/5-1-setupclustercachemanagement/",
	"title": "Setup cluster cache management",
	"tags": [],
	"description": "",
	"content": "Configuring Cluster Cache Management (CCM) Following are the steps to configure and enable the use of CCM on your Aurora PostgreSQL cluster\nModify the Amazon Aurora DB Cluster Parameters related to CCM. Sign in to the AWS Management Console and select Parameter Groups on the Amazon RDS console.\nIn the list, choose the DB cluster parameter group for your Aurora PostgreSQL DB cluster. The DB cluster must use a parameter group other than the default, because you can\u0026rsquo;t change values in a default parameter group. For more information, see Creating a DB Cluster Parameter Group.\nClick Edit under the Actions menu.\nSet the value of the apg_ccm_enabled cluster parameter to 1 and click on Save Changes.\nFor cluster cache management, make sure that the promotion priority is tier-0 for the writer DB instance of the Aurora PostgreSQL DB cluster. The promotion tier priority is a value that specifies the order in which an Aurora reader is promoted to the writer DB instance after a failure. Valid values are 0–15, where 0 is the first priority and 15 is the last priority. Select Databases in the Amazon RDS console.\nChoose the Writer DB instance of the Aurora PostgreSQL DB cluster and click on Modify\nThe Modify DB Instance page appears. Under Additional configuration, choose tier-0 for Failover Priority. Choose Continue and check the summary of modifications. To apply the changes immediately after you save them, choose Apply immediately and click Modify DB Instance to save your changes. For more information about setting the promotion tier, see Modify a DB Instance in a DB Cluster and the Promotion tier setting . See also Fault Tolerance for an Aurora DB Cluster. Next, set one reader DB instance for cluster cache management. To do so, choose a reader from the Aurora PostgreSQL cluster that is the same instance class and size as the writer DB instance. For example, if the writer uses db.r5.xlarge, choose a reader that uses this same instance class type and size. Then set its promotion tier priority to 0. The promotion tier priority is a value that specifies the order in which an Aurora replica is promoted to the primary DB instance after a failure. Valid values are 0 to 15, where 0 is the highest and 15 the lowest priority. In the navigation pane, choose Databases. Choose the Reader DB instance of the Aurora PostgreSQL DB cluster and click on Modify The Modify DB Instance page appears. Under Additional configuration, choose tier-0 for Failover Priority. Choose Continue and check the summary of modifications. To apply the changes immediately after you save them, choose Apply immediately and click Modify DB Instance to save your changes. Verifying if CCM is enabled Click on the DB identifier with the cluster name you created as a part of the CloudFormation stack or manually.\nUnder Connectivity and Security section, you will notice 2 different endpoints. The one with type Writer is the cluster endpoint (for read-write connections) and the one with type Reader is the reader endpoint (for read-only connections).\nOpen a cloud9 terminal window by referring Open Cloud9 Terminal Window section and using psql command line connect to the Aurora PostgreSQL DB cluster writer end point. Run the following SQL commands to check the cluster cache management status: psql \\x\rselect * from aurora_ccm_status(); If the Cluster Cache management is not enabled, querying aurora_ccm_status() will display the below output: aupglab=\u0026gt; \\x Expanded display is on. mylab=\u0026gt; select * from aurora_ccm_status(); ERROR: Cluster Cache Manager is disabled\n"
},
{
	"uri": "//localhost:1313/vi/2-preparation/2-1-createvpc/",
	"title": "Tạo VPC",
	"tags": [],
	"description": "",
	"content": " Truy cập giao diện VPC console và chọn Create VPC. Tại mục Resources to create, chọn VPC and more.\nĐặt tên cho VPC và chọn CIDR block. Khối CIDR là dải địa chỉ IP sẽ có sẵn cho VPC của bạn. Đảm bảo chọn khối CIDR đủ lớn cho nhu cầu của bạn nhưng không lớn đến mức gây lãng phí địa chỉ IP. Chọn giá trị cho Number of public subnets, Number of private subnets và NAT Gateway.\nXem lại cấu hình của VPC và Click Create VPC "
},
{
	"uri": "//localhost:1313/vi/2-preparation/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Các bước chuẩn bị sử dụng một số dịch vụ sau:\nAmazon VPC network configuration with public and private subnets Database subnet group and relevant security groups for the Aurora PostgreSQL cluster and AWS Cloud9 environment AWS Cloud9 configured with the software components needed for the labs Custom cluster and DB instance parameter groups for the Amazon Aurora PostgreSQL cluster, enabling some extensions and useful parameters The master database credentials will be store in AWS Secrets Manager Nội dung Tạo VPC Tạo Security Group Tạo EC2 Tạo Subnet Group và Parameter Group Tạo Aurora PostgreSQL Cluster Cấu hình Cloud9 và Initialize Database "
},
{
	"uri": "//localhost:1313/vi/5-clustercachemanagement/5-2-benchmarkingwithclustercachemanagement/",
	"title": "Database and Schemas",
	"tags": [],
	"description": "",
	"content": "Welcome to PostgreSQL! If this is your first time looking at PostgreSQL, we encourage you to check out the official About PostgreSQL webpage.\nIn this module, we are going to explore Databases and Schemas.\nThis chapter assumes you have setup and configured pgAdmin. If you haven\u0026rsquo;t, please complete the pgAdmin module before proceeding.\nExplore Databases 1.In your pgAdmin tool, click the \u0026gt; in front of rdspg-fcj-labs to expand it.\nYou see 3 breakouts: Databases, Login/Group Roles, and Tablespaces.\nIn this section, we will focus on Databases. And we\u0026rsquo;ll cover Login/Group Roles in a later section.\n2.Expand the Databases node.\nFrom a terminology standpoint, the PostgreSQL instance (rdspg-fcj-labs) you have created is known as a PostgreSQL cluster. A cluster contains one or more databases. While the users/roles of a cluster are shared across a cluster, no data is shared across databases. In other words, when a customer connects to a cluster, that connection is required to specify the database it wants to work with and that connection can only work within a single database at a time.\nyou see a handful of databases within the pglab cluster.\nWhat is the `rdsadmin` database ?\rThe database named rdsadmin is a database that is reserved for use by the RDS/Aurora control plane.\r3.Right-click on the Databases node and choose Create, then click Databases\n4.Name the database first_database (but don\u0026rsquo;t save it yet)\nThe database has an owner. This role can control and assign permissions for this database to other roles. The owner defaults to the role you are currently logged in with pgAdmin. Also note that you can alter the owner of most PostgreSQL objects even after they are originally created.\n5.Now click on the Definition tab\nThere are various settings that can be changed. You don\u0026rsquo;t need to change anything for now.\n6.Click on the SQL tab\nThe SQL tab shows you a preview of the generated SQL command that pgAdmin is going to run.\n7.Click Save 8.Find your new database in the navigator and expand it. Explore Schemas A database contains one or more named schemas, which in turn contain tables and other objects like views and functions. The objects in a given PostgreSQL schema can be owned by different users and the schema name has no implied correlation to the name of the schema owner.\nAs described in the PostgreSQL Documentation\n\u0026quot; The same object name can be used in different schemas without conflict; for example, both schema1 and myschema may contain tables named mytable. Unlike databases, schemas are not rigidly separated: a user may access objects in any of the schemas in the database he is connected to, if he has privileges to do so.\nThere are several reasons why one might want to use schemas:\nTo allow many users to use one database without interfering with each other. To organize database objects into logical groups to make them more manageable. Third-party applications can be put into separate schemas so they cannot collide with the names of other objects. Schemas are analogous to directories at the operating system level, except that schemas cannot be nested.\u0026quot;\n1.Expand the Schemas node and see a default public schema.\n2.Right-click on the Schemas node and choose Create, then click Schema.\n3.Name the schema first_schema\nThe schemas have an owner and also have security permissions and default privileges for new objects created in the schema (you can click on the Security tab and the Default Permissions tab in the Create Schema dialog if you want).\n4.Click Save to create the new schema.\nPostgreSQL schemas can be different from how other databases like Oracle implement schemas. In Oracle, schemas are directly mapped 1:1 to users. In PostgreSQL, schemas are not coupled directly to a specific user(role).\nAs discussed in the documentation ,\n\u0026ldquo;In the SQL standard, the notion of objects in the same schema being owned by different users does not exist. Moreover, some implementations do not allow you to create schemas that have a different name than their owner. In fact, the concepts of schema and user are nearly equivalent in a database system that implements only the basic schema support specified in the standard. Therefore, many users consider qualified names to really consist of username.tablename. This is how PostgreSQL will effectively behave if you create a per-user schema for every user. Also, there is no concept of a public schema in the SQL standard. For maximum conformance to the standard, you should not use (perhaps even remove) the public schema.\u0026rdquo;\nA note about the search_path Referencing objects via Qualified names, such as first_schema.first_table, is tedious to write, and hard-coding a particular schema name into an application is not ideal. The solution is to use unqualified names, such as first_table and this is made possible via the PostgreSQL search_path.\nAs discussed in the documentation ,\n\u0026ldquo;The system determines which table is meant by following a search_path, which is a list of schemas to look in. The first matching table in the search path is taken to be the one wanted. If there is no match in the search path, an error is reported, even if matching table names exist in other schemas in the database.\nThe first schema named in the search path is called the current schema. Aside from being the first schema searched, it is also the schema in which new tables will be created if the CREATE TABLE command does not specify a schema name.\u0026rdquo;\nBy default, the search_path is set to $user,public. As the documentation states\n\u0026ldquo;The first element specifies that a schema with the same name as the current user is to be searched. If no such schema exists, the entry is ignored. The second element refers to the public schema that we have seen already.\u0026rdquo;\nIt should be noted that PostgreSQL does not have the concept of synonyms like certain other databases. You can use the search_path to handle some, but not all, of the capabilities that synonyms offer. For an example of implementing other synonym-like functionality in PostgreSQL, see this blog post .\nCongratulations!\nYou have learned the basics about PostgreSQL Databases and Schemas.\u0026mdash; title : \u0026ldquo;Database and Schemas\u0026rdquo; date : \u0026ldquo;r Sys.Date()\u0026rdquo; weight : 2 chapter : false pre : \u0026quot; 2.2. \u0026quot; Welcome to PostgreSQL! If this is your first time looking at PostgreSQL, we encourage you to check out the official About PostgreSQL webpage.\nIn this module, we are going to explore Databases and Schemas.\nThis chapter assumes you have setup and configured pgAdmin. If you haven\u0026rsquo;t, please complete the pgAdmin module before proceeding.\nExplore Databases 1.In your pgAdmin tool, click the \u0026gt; in front of rdspg-fcj-labs to expand it.\nYou see 3 breakouts: Databases, Login/Group Roles, and Tablespaces.\nIn this section, we will focus on Databases. And we\u0026rsquo;ll cover Login/Group Roles in a later section.\n2.Expand the Databases node.\nFrom a terminology standpoint, the PostgreSQL instance (rdspg-fcj-labs) you have created is known as a PostgreSQL cluster. A cluster contains one or more databases. While the users/roles of a cluster are shared across a cluster, no data is shared across databases. In other words, when a customer connects to a cluster, that connection is required to specify the database it wants to work with and that connection can only work within a single database at a time.\nyou see a handful of databases within the pglab cluster.\nWhat is the `rdsadmin` database ?\rThe database named rdsadmin is a database that is reserved for use by the RDS/Aurora control plane.\r3.Right-click on the Databases node and choose Create, then click Databases\n4.Name the database first_database (but don\u0026rsquo;t save it yet)\nThe database has an owner. This role can control and assign permissions for this database to other roles. The owner defaults to the role you are currently logged in with pgAdmin. Also note that you can alter the owner of most PostgreSQL objects even after they are originally created.\n5.Now click on the Definition tab\nThere are various settings that can be changed. You don\u0026rsquo;t need to change anything for now.\n6.Click on the SQL tab\nThe SQL tab shows you a preview of the generated SQL command that pgAdmin is going to run.\n7.Click Save 8.Find your new database in the navigator and expand it. Explore Schemas A database contains one or more named schemas, which in turn contain tables and other objects like views and functions. The objects in a given PostgreSQL schema can be owned by different users and the schema name has no implied correlation to the name of the schema owner.\nAs described in the PostgreSQL Documentation\n\u0026quot; The same object name can be used in different schemas without conflict; for example, both schema1 and myschema may contain tables named mytable. Unlike databases, schemas are not rigidly separated: a user may access objects in any of the schemas in the database he is connected to, if he has privileges to do so.\nThere are several reasons why one might want to use schemas:\nTo allow many users to use one database without interfering with each other. To organize database objects into logical groups to make them more manageable. Third-party applications can be put into separate schemas so they cannot collide with the names of other objects. Schemas are analogous to directories at the operating system level, except that schemas cannot be nested.\u0026quot;\n1.Expand the Schemas node and see a default public schema.\n2.Right-click on the Schemas node and choose Create, then click Schema.\n3.Name the schema first_schema\nThe schemas have an owner and also have security permissions and default privileges for new objects created in the schema (you can click on the Security tab and the Default Permissions tab in the Create Schema dialog if you want).\n4.Click Save to create the new schema.\nPostgreSQL schemas can be different from how other databases like Oracle implement schemas. In Oracle, schemas are directly mapped 1:1 to users. In PostgreSQL, schemas are not coupled directly to a specific user(role).\nAs discussed in the documentation ,\n\u0026ldquo;In the SQL standard, the notion of objects in the same schema being owned by different users does not exist. Moreover, some implementations do not allow you to create schemas that have a different name than their owner. In fact, the concepts of schema and user are nearly equivalent in a database system that implements only the basic schema support specified in the standard. Therefore, many users consider qualified names to really consist of username.tablename. This is how PostgreSQL will effectively behave if you create a per-user schema for every user. Also, there is no concept of a public schema in the SQL standard. For maximum conformance to the standard, you should not use (perhaps even remove) the public schema.\u0026rdquo;\nA note about the search_path Referencing objects via Qualified names, such as first_schema.first_table, is tedious to write, and hard-coding a particular schema name into an application is not ideal. The solution is to use unqualified names, such as first_table and this is made possible via the PostgreSQL search_path.\nAs discussed in the documentation ,\n\u0026ldquo;The system determines which table is meant by following a search_path, which is a list of schemas to look in. The first matching table in the search path is taken to be the one wanted. If there is no match in the search path, an error is reported, even if matching table names exist in other schemas in the database.\nThe first schema named in the search path is called the current schema. Aside from being the first schema searched, it is also the schema in which new tables will be created if the CREATE TABLE command does not specify a schema name.\u0026rdquo;\nBy default, the search_path is set to $user,public. As the documentation states\n\u0026ldquo;The first element specifies that a schema with the same name as the current user is to be searched. If no such schema exists, the entry is ignored. The second element refers to the public schema that we have seen already.\u0026rdquo;\nIt should be noted that PostgreSQL does not have the concept of synonyms like certain other databases. You can use the search_path to handle some, but not all, of the capabilities that synonyms offer. For an example of implementing other synonym-like functionality in PostgreSQL, see this blog post .\nCongratulations!\nYou have learned the basics about PostgreSQL Databases and Schemas.\n"
},
{
	"uri": "//localhost:1313/vi/5-clustercachemanagement/",
	"title": "Start with PostgreSQL",
	"tags": [],
	"description": "",
	"content": "This lab contains following tasks: Content pgAdmin Database and Schemas Tables and Datatypes Basic DML Role and Users Procedural Code Catalog and Data dictionary Session parameters "
},
{
	"uri": "//localhost:1313/vi/2-preparation/2-2-createsg/",
	"title": "Tạo Security Group ",
	"tags": [],
	"description": "",
	"content": "Tạo EC2 security group trong AWS console Truy cập giao diện EC2 console.\nTại ngăn điều hướng, chọn Security Groups.\nChọn Create Security Group.\nTại mục VPC, chọn VPC mà bạn muốn tạo security group.\nTại mục Security group name, đặt tên cho security group.\nTại mục Description, nhập mô tả cho security group. Chỉnh sửa Inbound Rule \u0026amp; Outbound Rule Click Create. Bạn đã tạo thành công security group cho EC2 instance\nTạo Database security group trong AWS console: Truy cập giao diện EC2 console.\nTại ngăn điều hướng, chọn Security Groups.\nChọn Create Security Group.\nTại mục VPC, chọn VPC mà bạn muốn tạo security group.\nTại mục Security group name, đặt tên cho security group.\nTại mục Description, nhập mô tả cho security group. Chỉnh sửa Inbound Rule \u0026amp; Outbound Rule Click Create. Bạn đã tạo thành công security group cho Aurora PostgreSQL\n"
},
{
	"uri": "//localhost:1313/vi/9-testfaulttolerance/9-2-testamanualdbclusterfailover/",
	"title": "Test a manual DB cluster failover",
	"tags": [],
	"description": "",
	"content": "In this test, we will use a Python script to connect to the cluster endpoint and continuously run a monitoring query.\nYou will need to open an additional Cloud9 terminal window as shown below. You will execute commands in one and see the results in the other session.\nDownload the failover test script with command below:\nwget https://aupg-fcj-assets.s3.us-west-2.amazonaws.com/lab-scripts/simple_failover.py In one of the two terminal windows, run the failover test script using the following command:\npython /home/ec2-user/simple_failover.py -e $DBENDP -u $DBUSER -p $DBPASS -d $PGDATABASE In the second cloud9 window, execute the command to initiate the failover\naws rds failover-db-cluster --db-cluster-identifier aupg-fcj-labs Initially the script would be connecting to the writer node and executing the query. You will see a slight pause and a message \u0026ldquo;waiting for failover\u0026rdquo; when the failover is initiated. Subsequently the time elapsed to re-connect and the new writer node information is printed.\nSince we are using the cluster endpoint for the connection, there is a slight delay to propagate the DNS record changes for the new writer node. You will see that for a few seconds after the failover, we are still connected to the old writer node which is now the new reader node. Once the DNS record change for the cluster endpoint is propagated to the client machine (in this case the Cloud9 workstation), the script will indicate that it is connected to the Writer node.\nYou will receive two event notification emails for each failover you initiate, one indicating that a failover has started, and one indicating that it has completed.\n"
},
{
	"uri": "//localhost:1313/vi/6-databaseactivitystreaming/6-2-dbactivitystreamsinaction/",
	"title": "Verify DB instance",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/3-fastcloning/",
	"title": "Fast Cloning",
	"tags": [],
	"description": "",
	"content": "Fast Cloning là gì ? The Fast Cloning\rFast cloning đề cập đến một tính năng cho phép bạn tạo bản sao chính xác của cơ sở dữ liệu một cách nhanh chóng và hiệu quả. Bản sao này ban đầu chia sẻ cùng một bộ lưu trữ cơ bản với cơ sở dữ liệu gốc, giúp quá trình này nhanh hơn và tiết kiệm chi phí hơn nhiều so với các phương pháp truyền thống như sao lưu toàn bộ cơ sở dữ liệu hoặc khôi phục snapshot.\nDưới đây là một số điểm chính về fast cloning for Aurora PostgreSQL:\nSpeed: Không giống như các phương pháp truyền thống, có thể mất hàng giờ hoặc thậm chí vài ngày đối với cơ sở dữ liệu lớn, fast cloning có thể tạo bản sao chỉ trong vài phút, ngay cả đối với cơ sở dữ liệu nhiều terabyte.\nEfficiency: Bản sao ban đầu chia sẻ bộ lưu trữ với cơ sở dữ liệu nguồn, nghĩa là không cần sao chép dữ liệu vật lý. Điều này giúp tiết kiệm dung lượng và giảm chi phí lưu trữ.\nCopy-on-write: Khi thực hiện thay đổi đối với cơ sở dữ liệu nguồn hoặc bản sao, các trang dữ liệu mới sẽ được tạo thay vì sửa đổi các trang hiện có. Điều này đảm bảo tính nhất quán của dữ liệu và giảm thiểu tác động lên cả hai cơ sở dữ liệu.\nMultiple uses: Fast cloning hữu ích cho nhiều tình huống khác nhau, bao gồm phát triển và thử nghiệm ứng dụng, cập nhật cơ sở dữ liệu, triển khai blue/green và chạy truy vấn phân tích mà không ảnh hưởng đến hoạt động sản xuất. Dưới đây là một số tài nguyên mà bạn có thể tìm hiểu thêm về Fast cloning cho Aurora PostgreSQL:\nAmazon Aurora documentation Amazon Aurora PostgreSQL blue/green deployment using fast database cloning Amazon Aurora Fast Database Cloning\nTrong phần thực hành này, chúng ta sẽ tìm hiểu quy trình tạo Fast Cloning Aurora. Chúng tôi sẽ quan sát sự khác biệt của dữ liệu và so sánh hiệu suất giữa cụm Aurora gốc và cụm sao chép.\nThiết lập thử nghiệm Fast Clone Hãy xem lại các bảng chúng ta đã tạo trong bước Tạo, Cấu hình Cloud9 và Khởi tạo cơ sở dữ liệu, bước này sẽ được sử dụng trong phần thực hành này.\nResoures name Value cloneeventtest Table to store the counter and the timestamp statusflag Table to store the status flag which controls the start/stop counter eventerrormsg Table to store error messages cloneeventproc Function to add data to the cloneeventtest table based on the start counter flag Tạo và xác minh ảnh hưởng của fast cloning đến hiệu năng Chạy pgbench wordload trên cụm chính\nTrước khi tạo Fast Clone của primary cluster, chúng tôi sẽ bắt đầu kiểm tra với pgbench để đo số liệu transaction per seconds (TPS) trên cụm chính. Mở Cloud9 terminal (terminal #1) và chạy lệnh sau. Lệnh này sẽ chạy trong 30 phút.\npgbench --progress-timestamp -M prepared -n -T 1800 -P 60 -c 8 -j 8 -b tpcb-like@1 -b select-only@20 \u0026gt; Primary_results.log Xác minh môi trường và chạy thử nghiệm phân nhánh mẫu\nĐể xác minh sự khác biệt dữ liệu trên cụm chính và cụm sao, chúng tôi sẽ thêm dữ liệu mẫu bằng cách sử dụng các bảng mẫu.\nChúng ta cần mở thêm một cửa sổ terminal Cloud9 (terminal #2) để kết nối với Aurora và chạy chức năng. Để mở thêm một cửa sổ terminal trên môi trường Cloud9 của bạn, hãy nhấp vào menu Window và chọn new Terminal.\nChạy các lệnh sau để xác minh cột delflag được đặt thành 0 trong bảng statusflag và không có dữ liệu nào trong bảng cloneeventtest. Thực thi hàm cloneeventproc() để bắt đầu thêm dữ liệu mẫu.\npsql\rselect * from statusflag;\rselect * from cloneeventtest;\rselect cloneeventproc(); Tại thời điểm này (chúng ta gọi là thời gian “T1”), pgbench workload đang chạy trên cụm DB nguồn và chúng ta cũng đang thêm dữ liệu mẫu vào bảng trên cụm chính cứ sau 10 giây.\nDừng việc tạo dữ liệu mẫu Đầu tiên, vào phút T1+5, chúng tôi sẽ dừng việc thực thi chức năng bằng cách đặt lại thủ công cột delflag trên table statusflag về 1. Mở thêm một terminal Cloud9 để kết nối với Aurora (terminal #3). Pgbench workload sẽ tiếp tục thực thi trên cụm nguồn chính ở terminal #1.\npsql\rupdate statusflag set delflag=\u0026#39;Y\u0026#39;; Quay trở lại terminal #2 nơi chúng ta đã chạy hàm cloneeventproc. Đợi ~60 giây cho đến khi bạn thấy hàm hoàn tất quá trình thực thi:\nselect cloneeventproc(); Hãy kiểm tra số hàng trong bảng cloneeventtest. Chúng ta sẽ thấy 5 hàng trở lên trong bảng:\nselect count(*) from cloneeventtest; Hãy đặt múi giờ thích hợp và kiểm tra các hàng trong bảng cloneeventtest:\nSET timezone = \u0026#39;Asia/Ho_Chi_Minh\u0026#39;;\rselect * from cloneeventtest; Tạo Fast Clone Cluster Khi quá trình thực thi dừng lại (sau thời gian T1+5 phút), chúng ta sẽ bắt đầu tạo Fast Clone của the primary cluster. pgbench workload sẽ tiếp tục trên cụm chính ở terminal #1.\nBây giờ, chúng tôi sẽ hướng dẫn bạn quy trình cloning a DB cluster. Cloning tạo ra một cụm cơ sở dữ liệu độc lập, riêng biệt với bản sao nhất quán của dữ liệu kể từ thời điểm bạn sao chép nó. Cloning cơ sở dữ liệu sử dụng giao thức sao chép khi ghi, trong đó dữ liệu được sao chép tại thời điểm dữ liệu thay đổi, trên cơ sở dữ liệu nguồn hoặc cơ sở dữ liệu nhân bản. Hai cụm này được tách biệt và không có tác động đến hiệu suất đối với cụm DB nguồn từ các hoạt động cơ sở dữ liệu trên bản sao hoặc ngược lại.\nSau đây là các bước để định cấu hình bản sao Cơ sở dữ liệu nhanh trên cụm Aurora PostgreSQL của bạn:\na. Đăng nhập vào AWS Management Console và truy cập Amazon RDS console .\nb. Trong ngăn điều hướng, chọn Databases và chọn DB có tên cụm mà bạn đã tạo. Nhấp vào menu Actions ở trên cùng và chọn Create clone. c. Nhập aupglabs-clone làm DB Instance Identifier và Capacity type Provisioned.\nTại mục Cluster storage configuration chọn Aurora Standard.\nTại mục Instance configuration chọn Memory optimized classes và db.r6g.large. Tại phần Connectivity, để lại với cài đặt mặc định\nTrong Additional Configuration, chọn DB cluster parameter group và DB parameter groups created trong menu thả xuống nhóm tham số cụm DB và nhóm tham số DB. Kích hoạt auto minor version upgrade.\nĐể các trường nhập còn lại ở giá trị mặc định và click Create clone. Khi bạn nhấp vào “Create clone”, cột status sẽ hiển thị trạng thái như “Creating”. Clone cluster sẽ sẵn sàng sau khoảng 10-15 phút. Cột trạng thái sẽ hiển thị là “Có sẵn” sau khi cụm nhân bản đã sẵn sàng.\nBắt đầu quá trình phân nhánh dữ liệu mẫu trên cụm chính Sau khi quá trình tạo Clone cluster được khởi động, chúng ta sẽ bắt đầu quá trình tạo dữ liệu mẫu trên cụm chính. Mọi dữ liệu mẫu được thêm từ thời điểm này trở đi chỉ được có trên cụm chính chứ không có trên cụm sao chép.\npsql truncate cloneeventtest; # This will empty the cloneeventtest table, removing all existing rows.Make sure you want to do this as it\u0026#39;s an irreversible operation.\rupdate statusflag set delflag=0; select count(*) from cloneeventtest;\rselect cloneeventproc(); Xác minh sự phân nhánh dữ liệu trên Clone Cluster Clone cluster sẽ sẵn sàng sau khoảng 15 phút hoặc lâu hơn (thời gian T1+~10-15 phút).\nBảng “cloneventtest” trên cụm được nhân bản phải có snapshot dữ liệu như nó tồn tại trên cụm chính ở ~T1+5, vì đó là thời điểm chúng ta bắt đầu tạo bản sao.\nSao chép Writer Endpoint cho aurora cluster được nhân bản của bạn bằng cách nhấp vào tên cụm và đi tới tab Connectivity \u0026amp; security.\nKết nối với Aurora cloned cluster từ termianl #3. Thay thế bên dưới bằng Writer endpoint cho Cloned Aurora cluster mà bạn đã sao chép ở trên.\npsql -h \u0026lt;Cloned Cluster Writer Endpoint\u0026gt; Và chạy lệnh sql để kiểm tra nội dung dữ liệu:\nselect count(*) from cloneeventtest;\rSET timezone = \u0026#39;Asia/Ho_Chi_Minh\u0026#39;;\rselect * from cloneeventtest; Dừng hàm đang chạy trên Primary aurora cluster (làm theo bước Stop the sample data generation) và chọn dữ liệu từ bảng cloneeventtest. Chúng ta sẽ thấy nhiều hàng hơn, như mong đợi.\nChạy pgbench workload trên Clone Cluster Chúng ta sẽ bắt đầu pgbench workload tương tự trên cụm bản sao mới được tạo như chúng tôi đã làm trên cụm chính trước đó ở bước #1. Thay thế bên dưới bằng Writer Endpoint cho Cloned Aurora cluster của bạn.\npgbench --progress-timestamp -M prepared -n -T 1800 -P 60 -c 8 -j 8 --host=\u0026lt;Cloned Cluster Writer Endpoint\u0026gt; -b tpcb-like@1 -b select-only@20 \u0026gt; Clone_results.log Xác minh số liệu pgbench trên cụm chính và cụm sao chép. Sau khi pgbench workload hoàn thành trên cả cụm chính và cụm sao chép, chúng ta có thể xác minh số liệu TPS từ cả hai cụm bằng cách xem tệp đầu ra. "
},
{
	"uri": "//localhost:1313/vi/2-preparation/2-3-createec2/",
	"title": "Tạo EC2 instance",
	"tags": [],
	"description": "",
	"content": "Để tạo phiên bản EC2 cho môi trường Cloud9, hãy làm theo các bước sau: Truy cập giao diện Amazon EC2 console.\nClick Launch Instance. Enter name your EC2 instance. Choose an AMI. For an app server, you can choose a Linux AMI, such as Amazon Linux 2.\nChoose an instance type. The instance type that you choose will depend on the requirements of your app server. For example, if you are running a high-traffic website, you will need a larger instance type with more CPU and memory. For Key Pair,choose your keypair you have created or click Create new key pair Configure the instance details. This includes things like the number of instances to launch, the network configuration, and the storage configuration.\nFor Network settings\nChoose VPC which contains EC2 app server Choose Subnet Enable Auto-assign public IP Add a security group for EC2 app server that you have created easier step . A security group is a firewall that controls incoming and outgoing traffic to your instance. Review and launch the instance Once the instance is launched, you can connect to it using an SSH client, such as MobaXterm or Putty. Once you are connected, you can install your app server and deploy your application.\n"
},
{
	"uri": "//localhost:1313/vi/9-testfaulttolerance/9-3-testingfaultinjectionqueries/",
	"title": "Testing fault injection queries",
	"tags": [],
	"description": "",
	"content": "In this test you will simulate a crash of the database engine service on the DB instance. This type of crash can be encountered in real circumstances as a result of out-of-memory conditions, or other unexpected circumstances.\nLearn more about fault injection queries\rFault injection queries provide a mechanism to simulate a variety of faults in the operation of the DB cluster. They are used to test the tolerance of client applications to such faults. They can be used to:\nSimulate crashes of the critical services running on the DB instance. These do not typically result in a failover to a reader, but will result in a restart of the relevant services. Simulate disk subsystem degradation or congestion, whether transient in nature or more persistent. Simulate read replica failures In one of the two terminal windows, run the failover test script using the following command:\npython /home/ec2-user/simple_failover.py -e $DBENDP -u $DBUSER -p $DBPASS -d $PGDATABASE Since we are using the cluster endpoint to connect, the motioning script is connected to the current writer node.\nOn the other Cloud9 terminal window, issue the following fault injection command. A crash of the PostgreSQL-compatible database for the Amazon Aurora instance will be simulated.\npsql -c \u0026#34;SELECT aurora_inject_crash (\u0026#39;instance\u0026#39;);\u0026#34; Wait and observe the monitoring script output. Once the crash is triggered, you should see an output similar to the example below.\nAs you see above, the instance was restarted and the monitoring script reconnected after a brief interruption.\n"
},
{
	"uri": "//localhost:1313/vi/6-databaseactivitystreaming/",
	"title": "Import data into PostgreSQl",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/4-queryplanmanagement/",
	"title": "Query Plan Management",
	"tags": [],
	"description": "",
	"content": "Với query plan management (QPM), bạn có thể kiểm soát các kế hoạch thực hiện cho một tập hợp các câu lệnh mà bạn muốn quản lý. Bạn có thể làm như sau:\nCải thiện tính ổn định của kế hoạch bằng cách buộc trình tối ưu hóa chọn từ một số ít các kế hoạch tốt đã biết. Tối ưu hóa kế hoạch tập trung và sau đó phân phối các kế hoạch tốt nhất trên toàn cầu. Xác định các chỉ mục không được sử dụng và đánh giá tác động của việc tạo hoặc xóa chỉ mục. Tự động phát hiện kế hoạch chi phí tối thiểu mới được trình tối ưu hóa phát hiện. Thử nghiệm các tính năng tối ưu hóa mới với ít rủi ro hơn vì bạn có thể chọn chỉ phê duyệt những thay đổi trong kế hoạch nhằm cải thiện hiệu suất. Để biết thêm chi tiết về Query Plan Management vui lòng tham khảo tài liệu chính thức Managing Query Execution Plans for Aurora PostgreSQL.\nCách nhanh nhất để kích hoạt QPM là sử dụng chức năng tự động ghi lại kế hoạch, cho phép ghi lại kế hoạch cho tất cả các câu lệnh SQL chạy ít nhất hai lần. Trong thí nghiệm này, chúng ta sẽ đi qua quy trình kích hoạt QPM với việc ghi lại kế hoạch tự động, cải tiến các kế hoạch truy vấn bằng cách chấp nhận chúng theo cách thủ công và sửa các kế hoạch truy vấn bằng cách sử dụng gợi ý tối ưu hóa.\nBắt đầu nhanh việc sử dụng QPM với automatic capture Dưới đây là các bước để cấu hình và kích hoạt QPM trên cụm Aurora PostgreSQL của bạn để tự động nắm bắt và kiểm soát các kế hoạch thực thi cho một tập hợp câu lệnh SQL.\nTùy chỉnh Amazon Aurora DB Cluster Parameters liên quan đến QPM. Truy cập Amazon RDS service console Parameters group section nằm bên trái của RDS console.\nTrong danh sách, hãy chọn parameter group cho Aurora PostgreSQL DB cluster của bạn. Cụm DB phải sử dụng nhóm tham số khác với mặc định vì bạn không thể thay đổi giá trị trong nhóm tham số mặc định. Để biết thêm thông tin, xem Creating a DB Cluster Parameter Group.\nNhấp vào Edit bên dưới Action. Trong trường lọc Parametr, nhập rds.enable_plan_management. Đặt value của rds.enable_plan_management thành 1 và nhấp vào Save changes. Nhấp vào tên nhóm tham số cơ sở dữ liệu DB instance parameter group và nhấp vào Edit. Chúng ta cần thay đổi hai tham số:\nSửa giá trị của tham số apg_plan_mgmt.capture_plan_baselines thành automatic Sửa giá trị của apg_plan_mgmt.use_plan_baselines thành true Bấm Save Changes để lưu thay đổi Nhấp vào Databases trên bảng điều hướng bên trái và đợi trạng thái của instance thay đổi thành available. Các thay đổi tham số sẽ có hiệu lực sau khi khởi động lại như được đề xuất trên tab cấu hình của Aurora writer và reader instances\nKhởi động lại writer và reader nodes bằng cách chọn vào nó và đi tới Actions menu.\nĐợi trạng thái của writer và reader nodes trở nên Available.\nTạo và xác minh apg_plan_mgmt extension cho DB instance. Mở Cloud9 terminal bằng cách sau [Open Cloud9 Terminal Window](https://catalog.us-east-1.prod.workshops.aws/workshops/098605dc-8eee-4e84-85e9-c5c6c9e43de2/en-US/lab1- 5-client/cloud9-terminal/) và tạo apg_plan_mgmt extension cho DB instance của bạn.\n```\rpsql\rCREATE EXTENSION apg_plan_mgmt;\rselect extname,extversion from pg_extension where extname='apg_plan_mgmt';\r```\rBạn sẽ thấy đầu ra tương tự như sau. Extension version sẽ khác nhau tùy thuộc vào Aurora PostgreSQL instance.\n![QMP](/images/4.1/5.png)\rXem lại tất cả các tham số liên quan đến QPM được sửa đổi thành giá trị phù hợp bằng cách chạy các truy vấn sau.\n```\rshow apg_plan_mgmt.capture_plan_baselines;\rshow apg_plan_mgmt.use_plan_baselines;\r\\q\r```\r![QMP](/images/4.1/6.png)\rChạy synthetic workload với automatic capture. Mở một trong Cloud9 terminal và chạy pgbench (một công cụ đo điểm chuẩn của PostgreSQL) để tạo một workload mô phỏng chạy các truy vấn tương tự trong một khoảng thời gian cụ thể. Khi bật tính năng thu nạp tự động, QPM sẽ ghi lại các gói cho mỗi truy vấn chạy ít nhất hai lần.\n```\rpgbench --progress-timestamp -M prepared -n -T 100 -P 1 -c 100 -j 100 -b tpcb-like@1 -b select-only@20\r# The following pgbench command runs for 100 seconds with 100 clients/db sessions and 100 job threads emitting progress every 1 second\r```\rĐợi lệnh trên kết thúc.\nMở một terminal khác trên Cloud9 để truy vấn bảng apg_plan_mgmt.dba_plans để xem các câu lệnh được quản lý và kế hoạch thực thi. Sau đó chạy các lệnh sau: psql\rSELECT sql_hash, plan_hash, status, enabled, sql_text FROM apg_plan_mgmt.dba_plans; Tắt tính năng automatic capture các gói truy vấn. Việc thu thập tất cả các gói bằng tính năng automatic capture có ít chi phí thời gian chạy và có thể được kích hoạt trong production. Chúng ta đang tắt tính năng automatic capture để đảm bảo rằng chúng ta không thu thập các câu lệnh SQL bên ngoài pgbench workload. Bạn có thể tắt tính năng này bằng cách đặt tham số apg_plan_mgmt.capture_plan_baselines thành off từ DB parameter group. Xác minh cài đặt parameter bằng PSQL. Vì apg_plan_mgmt.capture_plan_baselines là một tham số động nên nó không cần khởi động lại phiên bản để có hiệu lực. Sẽ mất 5-10 giây để giá trị tham số thay đổi.\nshow apg_plan_mgmt.capture_plan_baselines; Hãy xác minh rằng kế hoạch thực hiện cho một trong các câu lệnh được quản lý có giống với kế hoạch được QPM nắm bắt hay không. Thực hiện explain plan trên một trong các câu lệnh được quản lý. Output của explain plan cho thấy hàm băm SQL và hàm băm kế hoạch khớp với kế hoạch được QPM phê duyệt cho câu lệnh đó. explain (hashes true) UPDATE pgbench_tellers SET tbalance = tbalance + 100 WHERE tid = 200; # (hashes true): This is likely part of a specific testing or benchmarking framework and doesn\u0026#39;t directly affect the UPDATE statement itself. It might indicate a particular flag or configuration within the framework. Ngoài việc automatic plan capture, QPM còn có khả năng manual plan capture, cung cấp cơ chế nắm bắt các kế hoạch thực hiện cho các truy vấn có vấn đề đã biết. Nói chung, việc nắm bắt các kế hoạch một cách tự động được khuyến khích. Tuy nhiên, có những tình huống mà việc thu thập kế hoạch theo cách thủ công sẽ là lựa chọn tốt nhất, chẳng hạn như:\nBạn không muốn kích hoạt quản lý kế hoạch ở cấp Cơ sở dữ liệu, nhưng bạn chỉ muốn kiểm soát một vài câu lệnh SQL quan trọng. Bạn muốn lưu kế hoạch cho một tập hợp chữ hoặc giá trị tham số cụ thể đang gây ra sự cố về hiệu suất Khả năng thích ứng của QPM Plan với cơ chế plan evolution Nếu kế hoạch được tạo bởi trình tối ưu hóa không phải là kế hoạch được lưu trữ thì trình tối ưu hóa sẽ thu thập và lưu trữ nó dưới dạng kế hoạch mới chưa được phê duyệt để duy trì sự ổn định cho các câu lệnh SQL do QPM quản lý. Quản lý kế hoạch truy vấn cung cấp các kỹ thuật và chức năng để thêm, duy trì và cải thiện các kế hoạch thực hiện và do đó cung cấp khả năng thích ứng của Kế hoạch. Người dùng có thể hướng dẫn QPM theo yêu cầu hoặc định kỳ phát triển tất cả các gói được lưu trữ để xem liệu có gói chi phí tối thiểu nào tốt hơn bất kỳ gói nào được phê duyệt hay không.\nQPM cung cấp chức năng apg_plan_mgmt.evolve_plan_baselines để so sánh các gói dựa trên hiệu suất thực tế của chúng. Tùy thuộc vào kết quả thử nghiệm hiệu suất, bạn có thể thay đổi trạng thái của kế hoạch từ unapproved thành approved hoặc rejected. Thay vào đó, bạn có thể quyết định sử dụng chức năng apg_plan_mgmt.evolve_plan_baselines để tạm thời vô hiệu hóa một gói nếu gói đó không đáp ứng yêu cầu của bạn. Để biết thêm thông tin chi tiết về QPM Plan evolution, hãy xem Evaluating Plan Performance .\nĐối với trường hợp sử dụng đầu tiên, chúng ta sẽ xem qua một ví dụ về cách QPM giúp đảm bảo sự ổn định của kế hoạch trong đó các thay đổi khác nhau có thể dẫn đến sự suy giảm của kế hoạch.\nTrong hầu hết các trường hợp, bạn thiết lập QPM để ghi lại kế hoạch cho tất cả các câu lệnh chạy hai lần trở lên. uy nhiên, bạn cũng có thể ghi lại kế hoạch cho một tập hợp cụ thể các câu lệnh mà bạn chỉ định theo cách thủ công. Để thực hiện việc này, bạn đặt apg_plan_mgmt.capture_plan_baselines = off trong DB parameter group (là mặc định) và apg_plan_mgmt.capture_plan_baselines = manual\nBật tính năng chụp kế hoạch thủ công để hướng dẫn QPM ghi lại kế hoạch thực hiện của các câu lệnh SQL mong muốn theo cách thủ công. SET apg_plan_mgmt.capture_plan_baselines = manual; Chạy explain plan cho một truy vấn cụ thể để QPM có thể ghi lại được kế hoạch thực hiện (đầu ra sau đây cho explain plan được cắt bớt để ngắn gọn). explain (analyze, summary, hashes)\rSELECT Sum(delta),\rSum(bbalance)\rFROM pgbench_history h,\rpgbench_branches b\rWHERE b.bid = h.bid\rAND b.bid IN ( 1, 2, 3 ); Tắt tính năng thu thập thủ công các câu lệnh SQL mới cùng với các kế hoạch của chúng sau khi bạn nắm bắt kế hoạch thực hiện cho câu lệnh SQL mong muốn. QPM tiếp tục nắm bắt các kế hoạch mới cho các câu lệnh SQL được quản lý ngay cả sau khi tắt apg_plan_mgmt.capture_plan_baselines.\nSET apg_plan_mgmt.capture_plan_baselines = off; Xem kế hoạch truy vấn đã thu thập cho truy vấn mà bạn đã chạy trước đó. Cột plan_outline trong bảng apg_plan_mgmt.dba_plans hiển thị toàn bộ kế hoạch cho SQL. Để cho ngắn gọn, plan_outline không được hiển thị ở đây. SELECT sql_hash,\rplan_hash,\rstatus,\restimated_total_cost \u0026#34;cost\u0026#34;,\rsql_text\rFROM apg_plan_mgmt.dba_plans; Để hướng dẫn tối ưu hóa truy vấn sử dụng các gói đã chụp được phê duyệt hoặc ưu tiên cho các câu lệnh được quản lý của bạn, hãy đặt tham số apg_plan_mgmt.use_plan_baselines thành true. SET apg_plan_mgmt.use_plan_baselines = true; Để xem đầu ra của lệnh \u0026ldquo;explain plan\u0026rdquo; và xác nhận rằng kế hoạch được QPM chấp nhận được sử dụng bởi trình tối ưu truy vấn, bạn có thể thực hiện các bước sau: explain (analyze, summary, hashes)\rSELECT Sum(delta),\rSum(bbalance)\rFROM pgbench_history h,\rpgbench_branches b\rWHERE b.bid = h.bid\rAND b.bid IN ( 1, 2, 3 ); Để tạo một chỉ mục mới trên cột \u0026ldquo;bid\u0026rdquo; trong bảng \u0026ldquo;pgbench_history\u0026rdquo; và thay đổi cấu hình trình tối ưu truy vấn để buộc trình tối ưu truy vấn tạo ra một kế hoạch mới, bạn có thể thực hiện các bước sau: create index pgbench_hist_bid on pgbench_history(bid); Xem đầu ra của explain plan để thấy rằng QPM phát hiện một kế hoạch mới nhưng vẫn sử dụng kế hoạch đã được phê duyệt và duy trì sự ổn định của kế hoạch. Lưu ý dòng An Approved plan was used instead of the minimum cost plan. explain (analyze, summary, hashes)\rSELECT Sum(delta),\rSum(bbalance)\rFROM pgbench_history h,\rpgbench_branches b\rWHERE b.bid = h.bid\rAND b.bid IN ( 1, 2, 3 ); Chạy truy vấn SQL sau để xem kế hoạch mới và trạng thái của kế hoạch. Để đảm bảo sự ổn định của kế hoạch, QPM lưu trữ tất cả các kế hoạch mới được tạo cho truy vấn được quản lý trong QPM dưới dạng các kế hoạch chưa được phê duyệt. Kết quả đầu ra sau đây cho thấy có hai kế hoạch thực thi khác nhau được lưu trữ cho cùng một câu lệnh được quản lý, được thể hiện bằng hai giá trị plan_hash khác nhau. Mặc dù phương án thực hiện mới có chi phí tối thiểu (thấp hơn kế hoạch được phê duyệt) nhưng QPM vẫn tiếp tục bỏ qua các phương án chưa được phê duyệt để duy trì tính ổn định của kế hoạch.\nCột plan_outline trong bảng apg_plan_mgmt.dba_plans hiển thị toàn bộ kế hoạch cho SQL. Để cho ngắn gọn, plan_outline không được hiển thị ở đây.\nSELECT sql_hash,\rplan_hash,\rstatus,\restimated_total_cost \u0026#34;cost\u0026#34;,\rsql_text\rFROM apg_plan_mgmt.dba_plans; Sau đây là ví dụ về khả năng thích ứng của kế hoạch với QPM. Ví dụ này đánh giá kế hoạch chưa được phê duyệt dựa trên hệ số tăng tốc tối thiểu. Nó phê duyệt bất kỳ kế hoạch nào chưa được phê duyệt được ghi lại nhanh hơn ít nhất 10 phần trăm so với kế hoạch được phê duyệt. Để biết thêm thông tin chi tiết, hãy xem Evaluating Plan Performance in the Aurora documentation. SELECT apg_plan_mgmt.Evolve_plan_baselines (sql_hash, plan_hash, 1.1,\u0026#39;approve\u0026#39;)\rFROM apg_plan_mgmt.dba_plans\rWHERE status = \u0026#39;Unapproved\u0026#39;; Sau khi QPM đánh giá kế hoạch dựa trên yếu tố tốc độ, trạng thái kế hoạch sẽ thay đổi từ không được phê duyệt thành được phê duyệt. Tại thời điểm này, trình tối ưu hóa có thể chọn gói chi phí thấp hơn mới được phê duyệt cho báo cáo được quản lý đó. SELECT sql_hash,\rplan_hash,\rstatus,\restimated_total_cost \u0026#34;cost\u0026#34;,\rsql_text\rFROM apg_plan_mgmt.dba_plans; Xem đầu ra của explain plan để xem liệu truy vấn có đang sử dụng kế hoạch chi phí tối thiểu mới được phê duyệt hay không. explain (analyze, summary, hashes)\rSELECT Sum(delta),\rSum(bbalance)\rFROM pgbench_history h,\rpgbench_branches b\rWHERE b.bid = h.bid\rAND b.bid IN ( 1, 2, 3 ); "
},
{
	"uri": "//localhost:1313/vi/2-preparation/2-4-createpgsg/",
	"title": "Tạo Subnet Group và Parameter Group",
	"tags": [],
	"description": "",
	"content": "Để tạo DB subnet group trên AWS, hãy làm theo các bước sau: Truy cập giao diện Amazon RDS console\nTrong ngăn điều hướng, chọn Subnet groups và click vào Create DB Subnet Group. Tại mục Name và Description, nhập tên và mô tả cho DB group.\nTại mục VPC, chọn VPC mà bạn muốn tạo DB group. Chọn các subnet mà bạn muốn đưa vào DB subnet group của mình. Đảm bảo chọn subnet ở ít nhất hai Availability Zones (AZ) khác nhau. Chọn Create.\nDB subnet group của bạn sẽ được tạo và hiển thị trong danh sách của DB subnet groups.\nDưới đây là một số điều bổ sung cần lưu ý khi tạo DB subnet groups:\nBạn chỉ có thể tạo DB subnet group trong VPC nằm trong cùng AWS Region với cơ sở dữ liệu mà bạn định sử dụng. Bạn phải có ít nhất một subnet trong mỗi AZ mà bạn muốn triển khai DB instance của mình. Bạn không thể sửa đổi DB subnet group sau khi nó đã được tạo. Nếu bạn cần thay đổi các subnet trong DB subnet group của mình, bạn phải tạo một subnet mới. Bạn có thể sử dụng DB subnet group để tạo DB instance ở bất kỳ AZ nào trong VPC. Tạo Database Parameter Group Truy cập giap diện AWS RDS console, chọn Parameter Group, chọn Create parameter group. Tại phần Parameter group details\nTại mục Parameter group family, chọn aurora-postgresql15 Tại mục Type, chọn DB Parameter Group Tại mục Group Name, đặt tên cho parameter group Tại mục Description, nhập mô tả Click Create Thay đổi và kích hoạt một số cấu hình trong Parameter Group Truy cập Parameter Group console, click Action, chọn Edit Nhập shared_preload_libraries trong thanh tìm kiếm parameter, sau đó chọn shared_preload_libraries Click Save Changes\nVề shared_preload_libraries parameter Tham số Shared_preload_libraries đóng vai trò quan trọng trong việc định cấu hình phiên bản Aurora PostgreSQL của bạn. Mục đích:\nTham số này chỉ định thư viện dùng chung nào được tải trước khi Aurora PostgreSQL server của bạn khởi động. Việc tải trước các thư viện giúp giảm chi phí tải chúng theo yêu cầu khi cần, có khả năng cải thiện hiệu suất cho các chức năng cụ thể.\nNhững thư viện nào được tải sẵn? Built-in libraries: Một số chức năng cốt lõi nhất định của PostgreSQL dựa vào các thư viện dùng chung được tự động tải theo mặc định. Bạn không cần cấu hình chúng trong Shared_preload_libraries. Custom libraries: Bạn có thể chỉ định các thư viện chia sẻ bổ sung để được tải trước cho các nhu cầu cụ thể. Các thư viện này có thể là: PostgreSQL extensions: Dành cho các tính năng như full-text search hoặc xử lý dữ liệu không gian (geospatial data handling). Custom modules: Được phát triển bởi bạn hoặc các nhà cung cấp bên thứ ba cho các chức năng độc lập. Lưu ý quan trọng: Performance impact: Việc tải trước các thư viện không cần thiết có thể tiêu tốn bộ nhớ và ảnh hưởng tiêu cực đến thời gian khởi động. Chỉ nên tải trước các thư viện được sử dụng tích cực bởi ứng dụng của bạn. Security considerations: Hãy cẩn thận khi thêm các thư viện tùy chỉnh do tiềm ẩn các lỗ hổng về bảo mật. Đảm bảo rằng chúng đến từ các nguồn đáng tin cậy và được kiểm tra kỹ lưỡng. Restart requirement: Sửa đổi shared_preload_libraries yêu cầu khởi động lại phiên bản Aurora PostgreSQL của bạn để thay đổi có hiệu lực. Tạo Database Cluster Parameter Group Truy cập giao diện AWS RDS console, chọn Parameter Group, chọn Create parameter group. Ở phần Parameter group details\nTại mục Parameter group family, chọn aurora-postgresql15 Tại mục Type, chọn DB Cluster Parameter Group Tại mục Group Name, đặt tên cho parameter Tại mục Description, nhập mô tả cho parameter Chọn Create Thay đổi và kích hoạt một số cấu hình cho parameter group Đi đến Parameter Group console, click Action, chọn Edit Nhập log_rotation ở thanh tìm kiếm parameter,\nTùy chỉnh log_rotation_age value: 1440\nTùy chỉnh log_rotation_size value: 102400\nClick Save Changes\nAbout log_rotation_age \u0026amp; log_rotation_size parameter\nlog_rotation_age\rFunction:\nlog_rotation_age xác định số lần xoay tối đa tính bằng phút cho các tệp nhật ký riêng lẻ trong cụm. Khi tệp đạt đến giới hạn này, nó sẽ tự động được thay đổi và một tệp mới sẽ được tạo. Tham số này giúp quản lý dung lượng ổ đĩa bằng cách ngăn chặn các tệp nhật ký phát triển vô thời hạn. Configuration:\nKhông giống như standalone instance nơi bạn có thể đặt log_rotation_age trong tệp postgresql.conf hoặc thông qua dòng lệnh, tham số này cần được đặt cấu hình thông qua tùy chỉnh Aurora PostgreSQL parameter group. Bạn có thể đặt giá trị mong muốn trong nhóm tham số và áp dụng nó cho cụm của mình. Impact:\nViệc đặt giá trị log_rotation_age ngắn hơn sẽ dẫn đến việc thay đổi thường xuyên hơn và tệp nhật ký mới hơn nhưng cũng có thể tăng hoạt động I/O của ổ đĩa và có khả năng ảnh hưởng đến hiệu suất. số lần xoay dài hơn làm giảm việc thay đổi tệp nhưng vẫn giữ lại các nhật ký cũ hơn, điều này có thể không cần thiết cho nhu cầu của bạn. Important Notes:\nRDS log rotation feature: Mặc dù RDS console liệt kê log_rotation_age dưới dạng tham số có thể định cấu hình cho tính năng xoay vòng nhật ký tích hợp nhưng bảng điều khiển này hiện không có tác dụng trên các cụm Aurora PostgreSQL. Bạn vẫn cần sử dụng nhóm tham số tùy chỉnh để kiểm soát việc xoay vòng của tệp.\nCloudWatch Logs integration: Aurora PostgreSQL tự động truyền nhật ký tới CloudWatch Logs theo mặc định. Bạn có thể định cấu hình các chính sách lưu giữ theo số lần xoay trong CloudWatch để quản lý tổng số lần xoay vòng nhật ký sử dụng của dữ liệu, bất kể xoay vòng tệp. Recommendations:\nChọn giá trị log_rotation_age cân bằng giữa nhu cầu quản lý dung lượng ổ đĩa với việc lưu giữ đủ lịch sử nhật ký để khắc phục sự cố và phân tích.\nHãy cân nhắc việc theo dõi hiệu suất cụm của bạn và điều chỉnh giá trị tham số nếu cần.\nSử dụng CloudWatch Logs để lưu giữ và phân tích nhật ký lâu dài ngoài các chế độ xoay tệp do log_rotation_age quản lý.\nlog_rotation_size\rFunction:\nlog_rotation_size chỉ định kích thước tối đa (tính bằng kilobyte) cho một tệp nhật ký riêng lẻ trước khi nó tự động xoay và một tệp mới được tạo. Điều này giúp ngăn chặn sự phát triển quá mức của nhật ký và giữ cho thư mục nhật ký có thể quản lý được. Configuration:\nTương tự như log_rotation_age, bạn cần định cấu hình tham số này thông qua tùy chỉnh Aurora PostgreSQL parameter group. Đặt kích thước mong muốn tính bằng kilobyte trong nhóm tham số và áp dụng nó cho cụm của bạn. Impact:\nViệc chọn giá trị log_rotation_size nhỏ hơn sẽ kích hoạt việc xoay vòng thường xuyên hơn, nghĩa là các tệp nhật ký nhỏ hơn và mới hơn. Tuy nhiên, điều này có thể làm tăng hoạt động I/O của đĩa và ảnh hưởng một chút đến hiệu suất. Ngược lại, kích thước lớn hơn dẫn đến ít vòng quay hơn và có khả năng ghi nhật ký lớn hơn nhưng có thể tiêu tốn nhiều dung lượng ổ đĩa hơn. Important Notes:\nAutomatic file naming: Khi xoay tệp, Aurora PostgreSQL sẽ thêm các dấu thời gian hoặc số thứ tự vào tên tệp của chúng để duy trì ngữ cảnh lịch sử. RDS log rotation feature:: Tương tự như log_rotation_age, tính năng xoay vòng nhật ký RDS hiện không kiểm soát việc xoay vòng dựa trên kích thước trong các cụm Aurora PostgreSQL. Cách tiếp cận nhóm thông số tùy chỉnh là cần thiết. CloudWatch Logs integration: Bạn có thể sử dụng CloudWatch Logs với các chính sách lưu giữ dựa trên kích thước để lưu trữ hoặc xóa các tệp nhật ký đã xoay sau khi vượt quá một kích thước cụ thể. Recommendations:\nChọn giá trị log_rotation_size cân bằng giữa việc quản lý dung lượng ổ đĩa với nhu cầu phân tích nhật ký của bạn. Xem xét khối lượng và kích thước của các tệp điển hình của bạn để ước tính khoảng thời gian luân chuyển thích hợp. Theo dõi hiệu suất cụm của bạn và điều chỉnh giá trị tham số nếu cần thiết để tránh xoay quá mức hoặc tệp nhật ký lớn. Tận dụng CloudWatch Logs để quản lý và lưu giữ nhật ký lâu dài, không phụ thuộc vào các hoạt động xoay do log_rotation_size kiểm soát. Hãy nhớ rằng việc tối ưu hóa cả log_rotation_age và log_rotation_size cho phép bạn quản lý hiệu quả các tệp nhật ký của cụm Aurora PostgreSQL, đảm bảo có đủ dữ liệu để phân tích đồng thời hạn chế mức sử dụng ổ đĩa và các tác động tiềm ẩn đến hiệu suất. "
},
{
	"uri": "//localhost:1313/vi/2-preparation/2-5-createaupg/",
	"title": "Create Aurora PostgreSQL Database",
	"tags": [],
	"description": "",
	"content": "Để tạo Aurora PostgreSQL DB, hãy làm theo các bước sau: Truy cập giao diện Amazon RDS console. Click Create database.\nTại mục Database engine, chon PostgreSQL.\nTại mục Version, chọn phiên bản PostgreSQL mà bạn muốn sử dụng. Tại mục Template, chọn một template cho DB instance của bạn. template là cấu hình được định cấu hình sẵn cho DB instance. Tại mục Availability và Durability, tại mục DB instance identifier, đặt tên cho DB instance. Tại mục DB instance identifier, đặt tên cho database instance.\nTại mục Master username, đặt tên cho người dùng chính của database instance.\nTại mục Master password, đặt mật khẩu database instance. Tại mục Cluster storage configuration, chọn dung lượng lưu trữ mà bạn muốn phân bổ cho database instance của mình. Tại mục Instance configuration, chọn DB instance class mà bạn muốn sử dụng cho DB instance của mình. DB instance class sẽ xác định lượng CPU và bộ nhớ được phân bổ cho DB instancecủa bạn. Tại mục Connectivity,\nĐể các tùy chọn Compute resource và Network type ở giá trị mặc định. Đảm bảo tùy chọn cluster Publicly accessible được đặt thành No. Bỏ chọn tùy chọn Tạo proxy RDS. Tại mục DB subnet group, chọn DB subnet group mà bạn muốn sử dụng cho DB instance của mình.\nTại mục VPC security groups, chọn security groups mà bạn muốn sử dụng cho DB instance của mình. Mở rộng Additional configuration, Nhập 5432 cho database port\nĐể các tùy chọn Babelfish settings và Database authentication ở giá trị mặc định. Tại mục Monitoring,\nChọn hộp Bật Thông tin chi tiết về hiệu suất với thời gian lưu giữ cho Thông tin chi tiết về hiệu suất trong 7 ngày (bậc miễn phí) và sử dụng khóa AWS KMS aws/rds (mặc định) để theo dõi mã hóa dữ liệu. Tiếp theo, mở rộng phần Additional configuration - Enhanced Monitoring và chọn enable Enhanced Monitoring và chọn Granularity of 1 second. Mở rộng Additional configuration: Đặt tên cho database là aupglab. Chọn DB cluster parameter group có tên aupg-parametergroup . Tại mục DB parameter group, chọn aupg-pg Chọn khoảng thời gian Backup là 7 ngày. Chọn Enable encryption và chọn aws/rds (mặc định) cho Master key. Để truy xuất Log, hãy chọn PostgreSQL log. Để các tùy chọn Maintenance ở giá trị mặc định. Click Create database. Sẽ mất 5-10 phút để tạo Aurora cluster với nút ghi và nút đọc.\nHiển thị bản tóm tắt các tùy chọn cấu hình đã chọn\rAurora PostgreSQL 15.3 compatible cluster với DB class instance là db.r6g.large Cụm bao gồm writer and a reader DB instance ở các AZ khác nhau (có tính sẵn sàng cao) Sử dụng cấu hình lưu trữ Aurora Standard trong đó I/O được tính phí trên cơ sở trả cho mỗi request Được triển khai trong VPC với private subnets Kèm theo custom cluster và DB parameter groups Tự động sao lưu, giữ lại bản sao lưu trong 7 ngày Sử dụng rest encryption cho dữ liệu Đã bật tính năng Enhanced Monitoring và Performance Insights Với PostgreSQL database log đang được truy xuất sang CloudWatch Được tạo bằng cơ sở dữ liệu ban đầu có tên mylab Đã tắt tính năng deletion protection Lưu trữ thông tin xác thực Aurora PostgreSQL trong AWS Secrets Manager AWS Secrets Manager là gì?\rAWS Secrets Manager giúp bạn quản lý, truy xuất và xoay vòng thông tin xác thực cơ sở dữ liệu, thông tin xác thực ứng dụng, OAuth tokens, API keys và các thông tin bảo mật khác trong suốt vòng đời của chúng.\nSecrets Manager giúp bạn cải thiện tình trạng bảo mật của mình vì bạn không còn cần hard-coded thông tin xác thực trong mã nguồn ứng dụng nữa. Việc lưu trữ thông tin xác thực Secrets Manage giúp tránh khả năng bị xâm phạm bởi bất kỳ ai có ý đồ xấu. Bạn thay thế thông tin xác thực được hard-coded bằng lệnh gọi tới dịch vụ Secrets Manager để truy xuất thông tin xác thực khi bạn cần.\nVới Secrets Manager, bạn có thể cấu hình lịch xoay vòng tự động cho các secrets của mình. Điều này cho phép bạn thay thế secrets dài hạn bằng secrets ngắn hạn, giảm đáng kể nguy cơ bị xâm phạm. Vì thông tin xác thực không còn được lưu trữ cùng với ứng dụng nên thông tin xác thực luân phiên không còn yêu cầu cập nhật ứng dụng của bạn và triển khai các thay đổi đối với ứng dụng khách.\nĐối với các loại secrets khác mà bạn có thể có trong tổ chức của mình:\nAWS credentials – Chúng tôi khuyên dùng AWS Identity and Access Management.\nEncryption keys – Chúng tôi khuyên dùng AWS Key Management Service.\nSSH keys – Chúng tôi khuyên dùng Amazon EC2 Instance Connect.\nPrivate keys and certificates – Chúng tôi khuyên dùng AWS Certificate Manager.\nTruy cập giao dienen Secrets Manager console, sau đó chọn Store a new secret. Ở mục Secret type, chọn Credential for Amazon RDS database\nỞ mục Credential, nhập User name (nên đặt là masteruser) và password mà bạn đã cung cấp khi tạo cụm DB trước đó Để các tùy chọn Khóa mã hóa ở giá trị mặc định.\nTại Database, chọn mã định danh phiên bản DB mà bạn đã gán cho phiên bản của mình (ví dụ: aupg-fcj-labs).\nClick Next. Đặt tên secret là aupg-fcj-labs-DBMateruser-secret và nhập mô tả có liên quan cho secret đó, sau đó click Next. Cuối cùng, trong phần Configure automatic rotation, hãy chọn tùy chọn Disable automatic rotation. Click Next.\nTrong phần Review, bạn có thể kiểm tra các tham số cấu hình cho secret của mình trước khi nó được tạo. Ngoài ra, bạn có thể truy xuất code bằng các ngôn ngữ lập trình phổ biến để bạn có thể dễ dàng truy xuất các secret vào ứng dụng của mình. Nhấp vào Store ở cuối màn hình.\n"
},
{
	"uri": "//localhost:1313/vi/9-testfaulttolerance/",
	"title": "Querying data",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/11-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/2-preparation/2-6-configurecloud9andinitializedatabase/",
	"title": "Tạo, cấu hình Cloud9 và khởi tạo cơ sở dữ liệu",
	"tags": [],
	"description": "",
	"content": "Để tạo môi trường Cloud9, hãy làm theo các bước sau: Truy cập giao diện Amazon Cloud console, sau đó click Create enviroment Nhập tên cho môi trường của bạn và chọn tùy chọn Existing compute. Trong phần Existing compute, nhấp vào Copy key to clipboard Kết nối đến EC2 instance qua MobaXterm\nThực hiện theo lệnh bên dưới để lưu Public SSH key vào tệp authorized_keys\ncd .ssh\rnano authorized_keys Cài đặt Nodejs bằng lệnh bên dưới\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\r. ~/.nvm/nvm.sh\rnvm install 16 Tạo folder cloud9_env\nmkdir cloud9_env Kiểm tra đường dẫn của Nodejs\nwhich node Install jq packages sudo yum install jq Trở lại bước Create Cloud9 instance Tại mục User, nhập EC2 user Tại mục Host, nhập EC2 host Trong Additional details - optional Tại mục Environment path, nhập ~/cloud9_env Tại mục Path to Node.js binary, nhập đường dẫn mà bạn đã kiểm tra ở bước trước Sau đó click Create\nSau khi Successfully create Cloud9, click Open C9 install\nClick Next Click Next and leave everything ticked Click Finish Bây giờ bạn đã thành công created Cloud9 instance with existing compute\nCấu hình Cloud9 workstation Cấu hình AWS CLI của bạn bằng lệnh bên dưới: aws configure Nhập AWS Access Key ID Nhập AWS Secret Access Key ID Nhập Region name that you have handed-on lab Nhập Output format Trong terminal Cloud9, dán và chạy các lệnh sau.\nexport AWSREGION=`aws ec2 describe-availability-zones --output text --query \u0026#39;AvailabilityZones[0].[RegionName]\u0026#39;`\r# Replace your --db-cluster-identifier\rexport DBENDP=`aws rds describe-db-clusters --db-cluster-identifier aupg-fcj-labs --region $AWSREGION --query \u0026#39;DBClusters[*].Endpoint\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;`\r# This assumes a \u0026#34;Name\u0026#34; tag was added to your secret with value aupg-fcj-labs-DBMasterUser-secret\rSECRETARN=`aws secretsmanager list-secrets --filters Key=\u0026#34;name\u0026#34;,Values=\u0026#34;aupg-fcj-labs-DBMasterUser-secret\u0026#34; --query \u0026#39;SecretList[*].ARN\u0026#39; | jq -r \u0026#39;.[0]\u0026#39;`\r# If below command doesnt show you the secret ARN, you should manually set the SECRETARN variable by referring it from the AWS Secrets manager console\recho $SECRETARN\rCREDS=`aws secretsmanager get-secret-value --secret-id $SECRETARN --region $AWSREGION | jq -r \u0026#39;.SecretString\u0026#39;`\rexport DBUSER=\u0026#34;`echo $CREDS | jq -r \u0026#39;.username\u0026#39;`\u0026#34;\rexport DBPASS=\u0026#34;`echo $CREDS | jq -r \u0026#39;.password\u0026#39;`\u0026#34;\recho DBENDP: $DBENDP\recho DBUSER: $DBUSER Hãy xác nhận rằng bạn đã có kết quả cho các biến DBENDP và DBUSER. Nếu không, có thể là bạn chưa đặt tên Aurora cluster của mình là \u0026quot;aupg-fcj-labs\u0026quot; hoặc gắn thẻ bí mật của bạn với Key:Name và Value: aupg-fcj-labs-DBMasterUser-secret. Trong trường hợp đó, hãy thiết lập các biến DBENDP, DBUSER và DBPASS bằng cách thủ công trong cửa sổ dòng lệnh trước khi tiếp tục.\rBây giờ hãy chạy các lệnh này để lưu các biến này vào tệp cấu hình môi trường của bạn\nexport PGHOST=$DBENDP\rexport PGUSER=$DBUSER\rexport PGPASSWORD=\u0026#34;$DBPASS\u0026#34;\rexport PGDATABASE=aupglab\recho \u0026#34;export DBPASS=\\\u0026#34;$DBPASS\\\u0026#34;\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc\recho \u0026#34;export DBUSER=$DBUSER\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc\recho \u0026#34;export DBENDP=$DBENDP\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc\recho \u0026#34;export AWSREGION=$AWSREGION\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc\recho \u0026#34;export PGUSER=$DBUSER\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc\recho \u0026#34;export PGPASSWORD=\\\u0026#34;$DBPASS\\\u0026#34;\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc\recho \u0026#34;export PGHOST=$DBENDP\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc\recho \u0026#34;export PGDATABASE=aupglab\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc Bây giờ, bạn đã lưu các biến môi trường cụ thể của PostgreSQL trong tệp khởi động Cloud9 Bash, điều này sẽ giúp việc đăng nhập vào Aurora PostgreSQL Cluster bằng psql trở nên thuận tiện hơn.\nKết nối, xác minh và khởi tạo phiên bản cơ sở dữ liệu Hãy đảm bảo môi trường Cloud9 và cơ sở dữ liệu Aurora PostgreSQL của bạn đã được thiết lập chính xác.\nKết nối với cơ sở dữ liệu aupglab đã được thiết lập trong cụm Aurora PostgreSQL và xác minh version của database engine bằng cách chạy lệnh sau trong terminal Cloud9 của bạn.\npsql -c \u0026#39;select version(),AURORA_VERSION();\u0026#39; Nếu đã thiết lập chính xác môi trường Cloud9 của mình, bạn sẽ thấy kết quả đầu ra tương tự như sau: Bây giờ, hãy xác minh user, database, host và port mà chúng tôi đang kết nối bằng lệnh sau:\npsql\rselect current_user, current_database(), :\u0026#39;HOST\u0026#39; host, inet_server_port() port;\r\\q Vì chúng tôi đang sử dụng Aurora cluster endpoint để kết nối nên chúng tôi đang kết nối với primary/writer DB instance của Aurora PostgreSQL cluster. Chạy các lệnh sau trong terminal Cloud9 của bạn để khởi tạo cơ sở dữ liệu PostgreSQL và chuẩn bị sẵn sàng cho các bước thực hành tiếp theo.\n# Bỏ qua các thông báo LỖI bên dưới.\rpsql aupglab -f /home/ec2-user/clone_setup.sql \u0026gt; /home/ec2-user/clone_setup.output\rnohup pgbench -i --fillfactor=100 --scale=100 mylab \u0026amp;\u0026gt;\u0026gt; /tmp/nohup.out Bỏ qua bảng không tồn tại các thông báo lỗi bên dưới: pgbench sẽ mất khoảng một phút để khởi tạo cơ sở dữ liệu. Sau khi hoàn thành, bạn có thể chuyển sang phòng thí nghiệm tiếp theo.\n"
},
{
	"uri": "//localhost:1313/vi/7-rdsperformanceinsights/",
	"title": "RDS Performance Insights",
	"tags": [],
	"description": "",
	"content": "This lab will demonstrate the use of Amazon RDS Performance Insights . Amazon RDS Performance Insights (RDS PI) monitors your Amazon RDS DB instance load so that you can analyze and troubleshoot your database performance.\nThis lab contains the following tasks:\nLoad sample data to the Aurora PostgreSQL DB cluster Understand the RDS Performance Insights interface Use RDS Performance Insights to identify performance issue High volume insert load on the Aurora DB cluster using pgbench High volume update load on the Aurora DB cluster using pgbench Load sample data to the Aurora PostgreSQL DB cluster First, download all the required scripts used in this lab. Open a cloud9 terminal window by referring Open Cloud9 Terminal Window section and paste the commands below.\ncd\rwget wget https://aupg-fcj-assets.s3.us-west-2.amazonaws.com/lab-scripts/aupg-scripts.zip\runzip aupg-scripts.zip Create sample HR schema by running the following commands on the Cloud9 terminal window:\ncd /home/ec2-user/aupg-scripts/scripts\rpsql -f postgres-hr.sql # runs a PostgreSQL script named postgres-hr.sql Understanding the RDS Performance Insights interface While the command is running, open the Amazon RDS service console in a new tab, if not already open.\nNext, select the desired DB instance to load the performance metrics for. For Aurora DB clusters, performance metrics are exposed on an individual DB instance basis. The different DB instances comprising a cluster may run different workload patterns, and might not all have Performance Insights enabled. For this lab, we are generating load on the Writer (Primary) DB instance only.\nOnce a DB instance is selected, you will see the main dashboard view of RDS Performance Insights. The dashboard is divided into two sections, allowing you to drill down from high level performance indicator metrics down to individual waits, queries, users and hosts generating the load.\nThe performance metrics displayed by the dashboard are a moving time window. You can adjust the size of the time window by clicking the displayed time duration at the top right hand corner of the interface and selecting a relative range (5m, 1h, 5h, 24h, 1w, custom range) or specifying an absolute range. You can also zoom into a specific period of time by selecting with your mouse pointer and dragging across the graph\nAll dashboard views are time synchronized. Zooming in will adjust all views, including the detailed drill-down section at the bottom.\nHere is a summary of all the sections of RDS Performance Insights console.\nSection Filters Description Database load Load can be sliced by waits (default), application, database, hosts, session types, SQL commands and users This metric is designed to correlate aggregate load (sliced by the selected dimension) with the available compute capacity on that DB instance (number of vCPUs). Load is aggregated and normalized using the Average Active Session (AAS) metric. A number of AAS that exceeds the compute capacity of the DB instance is a leading indicator of performance problems. Granular Session Activity Sort by Waits, SQL (default), Hosts, Users, Session types, applications and databases Drill down capability that allows you to get detailed performance data down to the individual commands. Amazon Aurora PostgreSQL specific wait events are documented in the Amazon Aurora PostgreSQL Reference guide. Metrics Dashboard Click Metrics-new tab beside Dimensions to view counter metrics This section plots OS metrics, database metrics and CloudWatch metrics all in one place, such as number of rows read or written, transactions committed, etc. These metrics are useful to identify causes of abnormal behavior. This is how the new metrics dashboard looks like.\nUse RDS Performance Insights to identify performance issue In this exercise, we will learn how to use Performance Insights and PostgreSQL extensions to analyze the top wait events and performance issues. We will run some insert and update load test cases using pgbench utility on employees table in the HR schema.\nCreate pg_stat_statements extension\nIn a new psql session, connect to mylab database and run the following SQL command:\nBe sure to use a new psql session, otherwise your pg_stat_statements view will be created under the hr schema.\npsql\rCREATE EXTENSION pg_stat_statements;\r\\q Now, we are ready to run some load on the Aurora Instance to understand the capabilities of RDS Performance Insights.\nHigh volume insert load on the Aurora DB cluster using pgbench\nOn the cloud9 terminal window, run pgbench workload using the below command:\npgbench -n -c 10 -T 300 -f /home/ec2-user/aupg-scripts/scripts/hrload1.sql \u0026gt; /tmp/pgload1-run1.log The hrload1.sql SQL script will ingest employee records using PL/pgSQL function add_employee_data. This function uses employee_seq to generate the next employee_id, randomly generate data including first_name, salary with department_id from departments table. Each function call will insert 5 records. This test will be executed for 5 minutes with 10 clients.\nReview the PI dashboard and check the top wait events, AAS (Average Active Sessions) for the duration.\nYou will find below top 3 wait events:\nIO:XactSync - In this wait event, a session is issuing a COMMIT or ROLLBACK, requiring the current transaction’s changes to be persisted. Aurora is waiting for Aurora storage to acknowledge persistence.\nCPU\nLWLock:Buffer_content - In this wait event, a session is waiting to read or write a data page in memory while another session has that page locked for writing.\nNote down the key metrics in the pgbench output such as latency average and tps.\ncat /tmp/pgload1-run1.log Now, lets check the top 5 queries by execute time and CPU Consumption. Run the below SQL query to understand the load caused by the above pgbench run using pg_stat_statements extension.\npsql -c \u0026#34;SELECT substring(query, 1, 50) AS short_query, round(total_exec_time::numeric, 2) AS total_exec_time, calls, round(mean_exec_time::numeric, 2) AS mean_exec_time, round((100 * total_exec_time / sum(total_exec_time::numeric) OVER ())::numeric, 2) AS percentage_cpu FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 5;\u0026#34; Explain psql command\r**psql -c**: Executes a SQL command directly from the command line.\\\rSELECT: Begins the SQL query.\nsubstring(query, 1, 50) AS short_query: Displays the first 50 characters of each query for brevity.\nround(total_exec_time::numeric, 2) AS total_exec_time: Shows the total execution time for each query, rounded to two decimal places.\ncalls: Indicates the number of times each query has been executed.\nround(mean_exec_time::numeric, 2) AS mean_exec_time: Shows the average execution time per call for each query.\nround((100 * total_exec_time / sum(total_exec_time::numeric) OVER ())::numeric, 2) AS percentage_cpu: Calculates the percentage of total CPU time consumed by each query.\nFROM pg_stat_statements: Accesses the pg_stat_statements view, which stores query execution statistics.\nORDER BY total_exec_time DESC: Sorts the results by total execution time in descending order (most resource-intensive queries first).\nLIMIT 5: Restricts the output to the top 5 results.\nLets rerun the same function with 50 inserts per execution and check the impact on wait events. Use hrload2.sql for this run.\npgbench -n -c 10 -T 300 -f /home/ec2-user/aurora-scripts/scripts/hrload2.sql \u0026gt; /tmp/pgload1-run2.log Go to PI dashboard and check the top wait events and top SQLs now and see if there are any changes. If you don\u0026rsquo;t see any new activity in the database load section, change the time range to last 5 minutes and click Apply. Then change it back to last 1 hour and click Apply.\nRerun the pg_stat_statements query to check resource consumption now.\npsql -c \u0026#34;SELECT substring(query, 1, 50) AS short_query, round(total_exec_time::numeric, 2) AS total_exec_time, calls, round(mean_exec_time::numeric, 2) AS mean_exec_time, round((100 * total_exec_time / sum(total_exec_time::numeric) OVER ())::numeric, 2) AS percentage_cpu FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 5;\u0026#34; If you compare the wait events for the two pgbench runs, you will notice that IO:XactSync related waits have reduced in the latest run\nCan you verify whether the overall throughput (in terms of number of inserts) has increased by comparing the throughput and latencies reported by pgbench between the runs?\ncat /tmp/pgload1-run2.log High volume update load on the Aurora DB cluster using pgbench In this exercise, we will run updates on the employee table using update_employee_data_fname and update_employee_data_empid functions. On the cloud9 terminal window, run pgbench update workload using the below command:\npgbench -n -c 10 -T 180 -f /home/ec2-user/aurora-scripts/scripts/hrupdname.sql \u0026gt; /tmp/pgload2-run1.log The hrupdname.sql SQL script will update employee salary details in employees table using PL/pgSQL function update_employee_data_fname. This function randomly selects the employee records and checks if their salary is within a range (min and max salary of their job), if not updates their salary using their first_name. Each function call will select 5 records randomly. This test will be executed for 3 minutes with 10 clients.\nGo to RDS PI dashboard. Check the top wait events and AAS for the run duration.\nTop wait event is:\nCPU\nAlso check the CPU utilization Cloudwatch metrics for the Aurora cluster by selecting the Monitoring tab, searching for cpu and expanding the CPUUtilization graph.\nUpdate the graph to display 1 minute average. As you can see the CPUUtilization reached ~100% during the update load test.\nLet’s look at the performance stats using pg_stat_statements extensions.\nRun the below command and observe the top 5 queries consuming CPU.\npsql -c \u0026#34;SELECT substring(query, 1, 50) AS short_query, round(total_exec_time::numeric, 2) AS total_exec_time, calls, round(mean_exec_time::numeric, 2) AS mean_exec_time, round((100 * total_exec_time / sum(total_exec_time::numeric) OVER ())::numeric, 2) AS percentage_cpu FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 5;\u0026#34; Let’s look at the explain plan used by the SQL statements in the PL/pgSQL function. In order to capture the explain plan in the logs, set the below DB parameters at your session level.\npsql\rset auto_explain.log_nested_statements=1;\rset auto_explain.log_min_duration=10; This will log any SQL statement including nested SQL statements which are taking more than 10ms in error/postgres.log with their corresponding explain plan.\nRun EXPLAIN ANALYZE to capture the explain plan as well as execute the query.\nEXPLAIN ANALYZE SELECT hr.update_employee_data_fname(10);\r\\q\r# hr.update_employee_data_fname(10): Calls the function update_employee_data_fname within the hr schema, passing the argument 10 Now, lets rerun the load using the SQL Script hrupdid.sql to use the employee_id column to update employees table.\nOn the cloud9 terminal window, run pgbench workload using the below command.\npgbench -n -c 10 -T 180 -f /home/ec2-user/aurora-scripts/scripts/hrupdid.sql \u0026gt; /tmp/pgload2-run2.log This will update employee salary details of employees using PL/pgSQL function update_employee_data_empid. This function randomly selects the employee records and checks if their salary is within a range (min and max salary of their job), if not updates their salary using their employee_id. Each function call will execute 5 records randomly. This test will be executed for 3 minutes with 10 clients.\nCompare the execution results using pg_stat_statements query again.\npsql -c \u0026#34;SELECT substring(query, 1, 50) AS short_query, round(total_exec_time::numeric, 2) AS total_exec_time, calls, round(mean_exec_time::numeric, 2) AS mean_exec_time, round((100 * total_exec_time / sum(total_exec_time::numeric) OVER ())::numeric, 2) AS percentage_cpu FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 5;\u0026#34; Compare the throughput and latencies reported by pgbench between the runs.\ncat /tmp/pgload2-run1.log\rcat /tmp/pgload2-run2.log "
},
{
	"uri": "//localhost:1313/vi/8-createdatasetandautoscale/",
	"title": "Create dataset and Auto Scale",
	"tags": [],
	"description": "",
	"content": "Aurora Auto Scaling enables your Aurora DB cluster to handle sudden increases in connectivity or workload by dynamically adjusting the number of Aurora Replicas for a provisioned Aurora DB cluster. When the connectivity or workload decreases, Aurora Auto Scaling removes unnecessary Aurora Replicas so that you don\u0026rsquo;t pay for unused DB instances.\nIn this lab, we will walk through how Aurora read replica auto scaling works in practice using a load generator script.\nThis lab contains the following tasks:\nConfigure aurora replica auto scaling Initialize pgbench and Create a Dataset Run a read-only workload Create a replica auto scaling policy You will add a read replica auto scaling configuration to the DB cluster. This will allow the DB cluster to scale the number of reader DB instances that operate in the DB cluster at any given point in time based on the load.\nClick on the Aurora cluster name and go to Logs \u0026amp; events tab. Click on the Add auto scaling policy button.\nEnter auroralab-autoscale-readers as the Policy Name. For the Target metric choose Average CPU utilization of Aurora Replicas. Enter a Target value of 20%. In a production use case this value may need to be set much higher, but we are using a lower value for demonstration purposes.\nNext, expand the Additional configuration section, and change both the Scale in cooldown period and Scale out cooldown period to a value of 180 seconds. This will reduce the time you have to wait between scaling operations in subsequent labs.\nIn the Cluster capacity details section, set the Minimum capacity to 1 and Maximum capacity to 2. In a production use case you may need to use different values, but for demonstration purposes, and to limit the cost associated with the labs we limit the number of readers to two.\nNext click Add policy.\nInitialize pgbench and Create a Dataset Open a Cloud9 terminal window by referring Open Cloud9 Terminal Window section and initialize pgbench to start the creation of dataset by pasting the command below in your terminal window.\npgbench -i --scale=1000 Data loading may take several minutes, you will receive similar output once complete: Run a read-only workload Once the data load completes successfully, you can run a read-only workload on the cluster (so that we can trigger our auto scaling policy). You will also observe the effects on the DB cluster topology.\nFor this step you will use the Reader Endpoint of the cluster. You can find the reader endpoint by going to the RDS Console - Databases section , clicking the name of the Aurora cluster and going to the Connectivity \u0026amp; security tab.\nRun the load generation script from your Cloud9 terminal window, replacing the [readerEndpoint] placeholder with the actual Aurora cluster reader endpoint:\npgbench -h [readerEndpoint] -c 100 --select-only -T 600 -C Now, open the Amazon RDS management console in a different browser tab.\nTake note that the reader node is currently receiving load. It may take a minute or more for the metrics to fully reflect the incoming load.\nAfter several minutes return to the list of instances and notice that a new reader is being provisioned in your cluster.\nIt will take 5-7 minutes to add a new replica. Once the new replica becomes available, note that the load distributes and stabilizes (it may take a few minutes to stabilize).\nYou can now toggle back to your Cloud9 terminal window, and press CTRL+C to quit the running pgbench job. After a while the additional reader will be removed automatically.\n"
},
{
	"uri": "//localhost:1313/vi/10-comparationrdspgandaupg/",
	"title": "Comparison RDS PostgreSQL and Aurora PostgreSQL",
	"tags": [],
	"description": "",
	"content": "\rWhat is AWS RDS PostgreSQL ?\rRDS PostgreSQL is a managed database service offered by Amazon Web Services (AWS) that makes it easy to set up, operate, and scale PostgreSQL deployments in the cloud. It handles many of the complex administrative tasks involved in managing a PostgreSQL database, allowing you to focus on developing and using your applications.\nHere\u0026rsquo;s how it works:\nDeployment: You choose the desired PostgreSQL version, instance size (compute and memory resources), storage type, and other configuration options. Provisioning: AWS handles the provisioning of the database instance, including installation, setup, and configuration. Management: RDS PostgreSQL automatically manages tasks like: Software patching and updates Backups and recovery Storage management Replication for high availability and read scaling Monitoring and performance tuning Access: You connect to your RDS PostgreSQL database using standard PostgreSQL clients and tools. Scaling: You can easily scale your database instance up or down as your needs change, without downtime. Key benefits of using RDS PostgreSQL:\nEase of use: Sets up in minutes with simple configuration options. Managed operations: Automates time-consuming administrative tasks. Cost-effectiveness: Offers pay-as-you-go pricing with no upfront costs. Scalability: Easily scales up or down to meet changing demands. High availability: Provides replication for failover and read scaling. Security: Secures data with encryption at rest and in transit. Compatibility: Works with standard PostgreSQL tools and applications. Common use cases for RDS PostgreSQL:\nWeb and mobile applications Data warehousing and analytics Enterprise resource planning (ERP) Customer relationship management (CRM) Content management systems (CMS) Internet of Things (IoT) applications What is AWS Aurora PostgreSQL ?\rAurora PostgreSQL, offered by Amazon Web Services (AWS), is a fully managed, highly scalable, and high-performance relational database service that\u0026rsquo;s fully compatible with PostgreSQL. It combines the best of both worlds: the simplicity and cost-effectiveness of open-source PostgreSQL with the speed, reliability, and advanced features of high-end commercial databases.\nHere\u0026rsquo;s a breakdown of its key features:\nScalability:\nScales virtually infinitely for both storage and compute capacity, unlike RDS PostgreSQL which has limitations. Automatically scales in increments of 10 GB for optimal performance. Read replicas are near real-time and minimize impact on the primary instance. Performance:\nUp to 5x faster than standard PostgreSQL, especially for read-heavy workloads. Offers low latency read replicas across multiple Availability Zones. Features like global database and cluster cache further boost performance. Durability and Availability:\nHighly durable with automatic backups and continuous replication. Automated failover to replicas in case of primary instance failure. Global database allows automatic failover across regions for disaster recovery. Other Features:\nServerless compute allows paying only for what you use. Up to 15 read replicas can be attached for increased read scalability. Integrates with other AWS services for simplified data management. Enhanced security features like encryption at rest and in transit. Performance: Aurora PostgreSQL: Up to 5x faster than traditional PostgreSQL and 3x faster than RDS PostgreSQL. Scales seamlessly without downtime. RDS PostgreSQL: Good performance for smaller workloads, but can struggle with high traffic or complex queries. Scaling requires downtime.\nBenchmarks Configure\nAurora PostgreSQL RDS PostgreSQL Instance type db.m1.lar5ge (2vCPU + 7.5Gb) db.m1.lar5ge (2vCPU + 7.5Gb) Region us-west-2a us-west-2a Client Side (running pgbench) EC2 instance in us-west-2a EC2 instance in us-west-2a Installed PG version 15.x 15.x Storage Encryption Enabled Enabled Multi-AZ/ Replication/ High-availability Disabled Disabled Benchmark details\nFollowing command below:\npgbench -c 10 -j 10 -t 500 -h [your endpoint] -U [your username] [dbname] Scalability: Aurora PostgreSQL: Scales automatically and continuously, without performance impact. Can handle massive datasets and millions of concurrent connections. RDS PostgreSQL: Requires manual scaling with limited options, leading to downtime and performance bottlenecks. Availability and Durability: Aurora PostgreSQL: Extremely high availability with automatic failover and multi-AZ backups. Provides point-in-time recovery up to the last five minutes. RDS PostgreSQL: Offers single-AZ deployments and manual backups. Failover requires configuration and potential data loss. Cost: Aurora PostgreSQL: Can be more expensive than RDS PostgreSQL, especially for low-traffic applications. However, cost savings can come from improved performance and reduced scaling needs. RDS PostgreSQL: Generally cheaper than Aurora PostgreSQL, but costs can quickly increase as you scale or require higher performance. Additional Factors: Features: Aurora PostgreSQL supports some features not available in RDS PostgreSQL, such as Babelfish for database migration and global databases. Compatibility: Both are compatible with PostgreSQL applications, but Aurora PostgreSQL has limitations on supported versions. Management: Both are fully managed services, but Aurora PostgreSQL handles more tasks automatically. Best practices Choose Aurora PostgreSQL for: high-traffic applications, scalability requirements, mission-critical databases, strict availability needs. Choose RDS PostgreSQL for: budget-sensitive applications, simple workloads, specific PostgreSQL features not available in Aurora, need for wider range of supported versions. "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]